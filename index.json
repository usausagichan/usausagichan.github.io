[{"categories":["Project"],"contents":"post thumb image: \u0026ldquo;images/featured-post/lipstick.jpg\u0026rdquo; description:\n####簡介 對品牌來說，藉由現有客戶引進新客戶有時是比大量投放廣告更有效率的方法。比如對手機遊戲來說，朋友是不是也有在玩很多時候會影響你繼續玩下去的意願。想像一下如果全班都在玩某款手遊，你是不是也會忍不住載來玩看看呢？因此很多手機遊戲經常會推出邀請朋友送道具的活動，為的就是要吸引你和你的朋友同時玩這款遊戲，增加新客-你的朋友的同時，也讓你們兩個在遊戲的留存率因為對方也在玩的關係跟著提高。 但是如果你是企劃，在推薦計畫推出前是不是得先用少部分的玩家先測試一下方案的效果呢？這時就需要用A/B Test來驗證方案效果。 這個專案便是用(https://datamasked.com/)網站中的資料練習A/B Testing的實作，確定某公司實施的推薦計劃是否有效（或有助於公司賺取更多的收入）。\n我認為推薦計劃的成功應該定義為： （1）通過推薦計劃找到有價值的用戶（即推薦用戶的消費高於普通用戶）， （2）促進銷售或增加整體消費。\n為了確定推薦計劃是否有效，我們需要回答以下問題： （1）推薦計劃的用戶是否比普通用戶消費更多？ （2）推薦計劃是否能增加收入？\n完整程式碼可見於 本連結 ####查看資料 先大概看過有哪些column、並檢查資料的格式是不是恰當的\n####Task(1)推薦計劃的用戶是否比普通用戶消費更多？ 為了回答這個問題，我將資料拆分為: 控制組:非來自推薦計畫的使用者(referrral=0) 實驗組:來自推薦計畫的使用者(referrral=1) 並進行A/B Test檢驗兩者是否有不同 在檢驗進行前我先大致看過資料的分佈和視覺化成果 比較上圖test_data和control_data可發現兩者起始日期不同(2015-10-31\u0026amp;2015-10-03)，推測是因為推薦計畫的開始日期是10/31的緣故，因此若要比較控制組和實驗組應該都取10/31後的資料。\n","permalink":"https://usausagichan.github.io/blog/abtest/","tags":["Python","A/B Testing"],"title":"A/B Testing - User referral Program"},{"categories":["Project"],"contents":"平時對化妝品完全沒有概念，但想幫女朋友或朋友挑唇膏當聖誕禮物？別擔心，不用辛苦的看一堆網路文章，觀察PTT網友的用字遣詞自然會告訴你該怎麼挑唇膏\n專案簡介 利用python 抓取PTT MakeUP版2022年9/6到12/28所有有關唇膏的文章，進行關鍵字篩選及統計後以K-mean分群法將顧客分成五大群，並對他們各自喜好的唇膏顏色做統計分析。\n在這個專案中，我定義留言者對關鍵字使用的多寡為他對關鍵字的需求或偏好。比如一位留言者有護唇膏的需求，我便假設他會在留言中多次提及唇膏。而K-means分群正可以將不同維度中量值相似的向量區分出來，在專案中對應到的就是對一些關鍵字使用程度類似的留言者，我們可以說他們的偏好相近。因此，藉由K-means分群便可以近一步了解市場上偏好各異的消費者族群。 專案中所使用到的code可見於 本連結\n1.爬取PTT貼文 為了了解秋冬流行的唇膏，我利用Beautiful Soup 套件抓取9/6到12/28所有文章的標題、文章、留言和作者及留言者，並篩選出標題或文章內包含「唇」的貼文，確保資料探討的內容和唇妝有關。我們可以利用jieba切詞切分出文章出現的字詞，切詞後的貼文可見於下圖 小技巧：切分關鍵詞後可以事先刪除常見字尾或贅詞、PTT符號節省後面處理資料的時間。此外，事先將dict.txt.big.txt載入jieba切詞的字典裡可以更好的切分繁體字詞。\n2.篩選關鍵字 為了使jieba套件更好的切出想要的關鍵字，需要將與唇膏有關的關鍵字事先加入jieba的字典裡。由於這個project想探討的是有關顧客對唇膏的偏好，因此我先在網路上搜尋有關挑選唇膏的大原則 1 和化妝方式、技巧的文章 2 3，看出大家選購唇膏原則上依循兩大要點:\n妝感，大致可分為水潤（亮面）、霧面及介於兩者之間的水霧三種，而相關產品又可分為唇膏、唇釉（唇露/唇萃）、唇蜜、口紅四種\n唇膏顏色，除了自身喜好和流行，女生也會依據自己的膚色選擇適合自己的顏色，比如粉色較適合皮膚白皙的女生而不是和小麥膚色的女生。另外還會考慮唇膏本身的顯色度、飽和度和能不能顯白等等\n化妝技巧的部分秋冬因為有嘴唇乾燥的問題會先上一層護唇膏，為了避免原來唇色影響唇膏顯色或沾黏的問題會先抹上蜜粉打底和遮瑕。此外，最近韓系的暈染唇妝也很流行。唇膏的薄擦或後擦、疊色則是因人喜好而異。其他還有關於唇膏在日常使用的掉色程度、保濕度、滋潤度等等的考量\n對妝容感覺的偏好我分為可愛、仙氣、性感、優雅知性等等的風格\n參考這些文章後，我將這些關鍵字和專有名詞加入 excel檔，並載入jieba的字典裡，再利用jieba切詞將文章標題和內文切成字詞後進行統計，並存成excel檔。 我們可以看到使用頻率最頻繁的十個字如圖所示：\n表中有一些和美妝無關或無法從字詞得到資訊的字詞（例如：都、喜歡、好看、擦、美\u0026hellip;）， 這些詞會妨礙我們的分群觀察，所以我將這些字去除。 去除無關的關鍵字後，根據字詞出現的頻率畫出文字雲：\n可以發現聲量最多的關鍵字有：唇膏、唇彩、霧面、秋冬、唇釉、護唇膏、唇紋等等，回去看PTT幾篇文可以發現秋天最流行的唇妝是霧面，且大家普遍有乾唇問題所以會去找護唇膏。\n另外，我假設出現頻率5次以上的字詞都是jieba切得比較精準的字，所以我判斷該字與唇膏有關後便會直接保留這些關鍵字。至於其他關鍵字我則用程式篩選\n至於我篩選這些出現頻率4次以下關鍵字的方式如下：\n觀察聲量較高的關鍵字，歸納出與這些關鍵字意思類似的字可能包含哪個字，例如化妝品產品或PTT網友表達霧面的字可能有霧光、柔霧、霧唇等等。而我利用程式篩選出所有包含霧的關鍵字，再看關鍵字的字面意思決定要不要將關鍵字保留。例如「噴霧」雖然也包含誤字，但顯然和霧面無關，因此我會刪除。而若該字與霧面有相似意思，例如「霧唇」，我會將該字保留\n由於有關顏色的關鍵字很雜又很廣，例如光是粉色可能就有「粉紅」、「粉」、「偏粉」、「粉嫩」等等的表達方式，因此我也用程式篩選出可能表達顏色的字，比如想找出所有表達粉紅的關鍵字就先篩選出所有包含「粉」的字再進行人為判斷。\n在找大家討論的顏色時，我除了會上網查秋冬流行的唇色（例如楓紅、奶茶棕等等），也會利用程式篩選出包含「色」的字，並參考這些字的出處文章，再決定是否將這個顏色納入關鍵字中（例如文章提及「白色」並不是指白色唇膏，而是唇膏盒的包裝）\n3. 整理關鍵字 在這些關鍵字中，許多字的字面不同，卻代表同一意思。比如「潤感」、「潤光」都在表達「潤澤」，於是我就建立excel表，將「潤感」、「潤光」儲存在「關鍵字」coulmn，「潤澤」儲存在「對應」coulmn。最後整理完的關鍵字和顏色無關的可見於字典.xlsx，和顏色有關的則存在顏色.xlsx。\n4. 根據不同留言帳號，統計出他們各自使用關鍵字的次數 想要分析每位留言者的偏好其中一個方式就是找到他們喜歡的關鍵字。在這個環節，我統計每則留言出現的目標關鍵字，再根據留言帳號疊加起來，得到每位留言者在他所有的留言中使用目標關鍵字的總數。\n然而光看留言有會無法知道留言者在探討的議題，這時我們需要回去看留言所指的內文在寫什麼。因此我也將留言所指的內文納入考量，以得到更完整的留言者想法。我們的目標是利用統計關鍵字在留言中出現的次數得知留言者的偏好。而比起內文，留言本身更能代表留言者。所以在計算每則留言出現的目標關鍵字次數時，我的算法是以一比九的權重將內文出現的關鍵字次數與留言中出現的關鍵字次數相加起來。\n在上一個環節，我建立了字面不同的相似關鍵字對應到同個字詞的表格。在統計目標關鍵字出現次數的過程中，每當關鍵字出現我就會利用這個表格將關鍵字對應到所屬的字詞類別，最後再相加起來。例如「潤感」、「潤光」都在表達「潤澤」，所以在統計完「潤光」、「潤感」出現次數後要把這兩個關鍵字相加起來，得到「潤澤」出現的次數。如此一來便能較精準的算出目標關鍵字真正的聲量，避免目標關鍵字因表達方式不同而在文章及留言被忽略的問題。\n在得到所有目標關鍵字在每則留言出現的個數後，我依據留言者將他們疊加起來，最後算出每位留言者使用目標關鍵字的次數，並用這些數字代表留言者對不同主題偏好的程度。\n5. K-means分群 在上一步我們得到每個留言者對每個關鍵字的使用次數，詳細資料可見於excel檔\n而這些關鍵字使用次數代表偏好程度，因此我們可以用K-Means分群法將這些統計量做向量分群，得到需求、偏好各字不同的族群，掌握市場上不同面貌的消費者。\n為了知道分群數多少是最好的，我寫了for迴圈將資料做多次k-means分群，分群數介於1~15之間。最後將分群數對inertia (每個點到所屬群質心距離的和，用來衡量分群的誤差)，結果如下\n分的群數愈多，通常 inertia會越小，當群數等於資料點時必為零，其中的道理和隨機森林切得越細在訓練資料的誤差上越小相似。而要衡量分多少群最好，除了要讓inertia盡可能的小，還要讓分群數盡可能的少。所以一般來說大多會選擇 inertia 變化開始明顯變小附近的轉折點。最後我選擇n=6作為分群數。\n在做k-means分群時，我只採用與顏色無關的關鍵字作為feature，減少分群的複雜度。我們也能看看分群後的需求不同的消費者是不是比較偏好某些顏色。\n視覺化成果 我們共可得到六群顧客，而由於group 2 只有1人因此我不討論它。以下是去除group 2資料，用Tableau視覺化的成果：\n從表示各群人數的圓餅圖我們能看到，group0 人數440人為最大宗，group 5 人數84人為第二大群，group 1、3、4人數20人以下為小眾。\n我用Tree map表示每群顧客對不同關鍵字的偏好程度，在Tree map中板塊越大者關鍵字出現次數越多，代表該族群消費者對該關鍵字越偏好，需求也越高。\n從這五張Tree map我們能看到：\n不管是哪群顧客，霧面、秋冬幾乎都是出現最多的關鍵字。這可能是因為秋冬最流行霧面唇妝。\ngroup 0為最大族群（440人），因此我定義該群為大眾流行，也代表大多數女孩的需求。\nGroup 0 大眾流行的Tree map告訴我們：\n＊在唇妝上大家最偏好流行的霧面，潤澤次之 ＊功能上她們最注重護唇，也很注重滋潤度和保濕度，喜歡用羊脂膏 ＊她們普遍擔心唇紋問題，可能是秋冬較乾燥且她們常用相較其他妝感較顯唇紋的霧面唇膏的緣故 ＊風格上他們較偏好可愛、少女風格 ＊除了護唇也很注重顯白，顯氣色的腮紅和紅唇討論度也蠻高的 ＊喜歡薄擦唇膏 group1 有8人，他們特別偏好日系妝容（相較其他群該關鍵字使用次數多），也很注重唇膏的滋潤度、唇紋問題。她們在擦唇膏前會先打底，顏色上會選可以顯白的，此外除了流行的霧面唇膏她們也偏好潤澤唇膏。 group 3 有18人，特別偏好自然妝容，比起其他群的女孩更注重唇部保養和氣色，且對香奈兒的超炫耀系列討論度特別高，顏色上會挑顯白、深色的顏色，也很注重唇膏的顯色，推測是喜歡歐美風格的女孩 Group 4 有17人，他們非常注重顯白，也喜歡深色唇膏。風格偏好溫柔可愛的日常風，與其他群不同的是她們特別偏好暈染唇妝，上唇膏前會打底薄擦，也會注重搭配眼妝。另外，他們似乎也偏好限量商品。因為他們喜歡暈染唇妝，所以我叫他們韓系女孩。 Group 5有84人，除了流行的霧面唇妝，她們注重絲絨、粉霧那種較朦朧的感覺，顏色上喜歡暖系，注重唇膏的顯色和潤澤。 各族群對顏色的偏好 在依留言者對唇膏的需求進行分類後，我也統計每個族群提到有關唇膏顏色關鍵字的次數作為判斷他們對顏色偏好的依據。\n為了方便比較不同族群間對各顏色的偏好程度，我將每個族群提及顏色關鍵字的次數統計起來並除以他們的人數，計算族群中平均每個人提及顏色關鍵字的次數作為比較的標準。\n視覺化後的結果如下圖：\n首先我們先分析每個族群喜歡的顏色：\n除了Group5 外，其他族群幾乎都是最偏好紅色系唇膏。 大眾流行以紅色為最大宗，粉色系其次，裸色系第三。其他還有紅棕色系、橘色系、奶油系質感唇膏的需求存在。 Group 1日系美眉偏好紅色與紅棕色系的唇膏，同時他們對土色系唇膏偏好度大於其他族群，因此我判斷他們喜歡紅中帶棕、紅中帶咖啡色的唇膏。另外，他們也偏好具奶油質感的唇妝。 Group 3喜歡歐美風、香奈兒超炫耀的女孩以紅色唇膏為需求最大宗，此外，他們也是除了Group4韓系女孩外對紅色系需求最高的族群。值得注意的是，他們對裸色系唇膏的需求比起其他族群更高，符合歐美女性的偏好。而比起其他族群，他們對茶色、紅棕、土色唇膏需求較少 Group 4韓系女孩對紅色唇膏需求最大，而且也是各系女孩中對紅色唇膏需求最大的。由前段分析推測可能是他們比起其他族群更注重顯白的緣故。另外，他們也偏好粉色、橘色較清新的色系，和日系女孩一樣也偏好奶油系質感的唇膏，對裸色、紅棕咖啡、土色茶色需求相對少。 Group 5慕斯女孩與其他系女孩不同，對紅色唇膏需求反而沒那麼大。他們喜歡橘色系唇膏，粉色系次之。呼應前段分析顯示他們偏好暖色系的部分。推測他們可能喜歡活潑清新的風格。 若將各色系顏色細分，各族群偏好則如下圖\n顏色偏好（顏色）\n較值得注意的地方是Group1日系女孩在紅棕色系中偏好栗子色;Group5慕斯女孩則偏好楓色，此外他們對粉色系的偏好也以玫瑰色為主，橘色系則是橙色與栗橘。\n如何將專案結果運用於實務 除了用來釐清市場需求，了解顧客族群的樣貌，這個結果可以應用在推薦系統上。我們可以搜集消費者在留言平台上的留言，然後萃取他使用的關鍵字，進行統計後丟入預先訓練好的K-means模型預測出他可能是屬於哪類型的消費者，再做個人化推薦。比如我們預測消費者是歐美系女孩，我們便可多推薦超炫耀唇膏或紅色、裸色系的唇膏。\n此外，我們也可以應映分析出來的市場需求決定怎麼推廣或改良我們的產品。從視覺化報表中，我們可以看到大眾的需求圍繞著霧面唇膏、護唇保濕、避免唇紋、顯白等等，所以我們便可朝著滿足這些需求的方向改良、廣告我們的唇膏。另外，大眾普遍喜歡可愛風格，我們便可找形象類似的女明星來代言產品。\n改進方向 這個專案是以搜集留言者關鍵字為導向，而我們對關鍵字選擇和了解程度會很大程度的影響分析結果。因此可以事先諮詢相關專家，選擇能精準描述唇膏相關需求的關鍵字，並了解關鍵字不同的表達方式，可能會比自己上網找文章或直接從jieba切分的字詞了解有效率且精準。\n","permalink":"https://usausagichan.github.io/blog/cosmetic/","tags":["Python","Tableau","Scraping","Social Media Monitoring and Analytic","Machine Learning"],"title":"PTT輿情分析-秋冬流行唇妝與顧客分群"},{"categories":["Project"],"contents":"​ 只要你是台股的投資者，相信你一定對元大0050並不陌生。元大0050是台灣最大的指數型基金(ETF)之一，而他所追蹤的指數就是台灣50指數，我們可以簡略的把這檔ETF看作定期追蹤台灣市值前50大的公司，並按照這50大公司的市值去分配投資組合的比例，且會根據這些公司市值的變化滾動式修正投資組合的名單或佔比。因此，從0050的投資組合佔比我們便可掌握台灣大致的產業分佈和台灣的主流企業。\n在這個project中，我先利用python從公開資訊觀測站(https://mops.twse.com.tw/mops/web/t78sb04_q2) 抓取元大0050歷年來的投資組合比例，然後用Tableau視覺化分析台灣產業分佈和主流企業的變化。\n關於爬取資料的部分，我將程式碼放在我的Github： https://github.com/usausagichan/data-mining-for-0050.Tw- ，有興趣的朋友可以參考一下。\n而以下文章我就直接呈現將這些資料視覺化的結果（https://public.tableau.com/app/profile/ctchen/viz/IndustryAnalysis_16698030444010/Dashboard1可見完整dashboard），並為此做一些分析。\n公開資訊觀測站的資料\n抓下來的資料如下圖，可以看到表中包含了股票名稱、產業類別和持股比率，欄目持股比率為單一公司股票佔比，持股比率.1為產業類別的佔比\n以下是我將今年Q3各產業和公司佔元大0050持股比率視覺化的結果：\n從文字雲和Tree map看台企主流企業與公司的板塊 :\n圖一\n​ 其中Treemap和文字雲的大小和顏色深淺代表產業及公司在元大0050中投資組合的佔比，也大致反映了台股中各大公司和產業的市值。由圖一中可以看到在今年(2022)年，台灣產業以半導體業為大宗，第二名是金融保險業，約分別佔元大0050持股約53.79%和15.86%，差距約3.39倍之多，再來就是其他電子業、通信網路業、電子零組件、電腦及週邊設備業、光電業等等的其他科技業和塑膠工業，還有像鋼鐵工業、食品工業、水泥工業等零星的傳統產業。而市值最大的公司為台積電，連第二名的鴻海也難以望其項背。\n圖二\n​ 若我們將眼光聚焦於半導體產業（圖二左）也不難看到台積電壓倒性的佔最大宗，甚至是次之的聯發科將近12.37倍之多。反觀第二名的金融保險產業則分布較為平均（圖二右），前五大公司都約佔比1.64%到1.47%。事實上這幾間公司的在元大0050佔比排名每季可能都會有所不同，佔比的高低也不完全反映市值。這是因為台指0050的計算還需要考慮到個股的公眾流通性，而在這幾家公司市值差距並沒有那麼懸殊的情況下，公眾流通性這個因素可能就會影響他們在元大0050持份的排名。\n​ 總結來說，台灣的產業尤其偏重半導體業和電子相關科技業及金融保險業。然而這些產業的就業門檻比起其他產業來得高，特別是半導體業幾乎由台積電一家公司所主導，使得分得到這些大公司資源的就業人口非常有限。根據工商日報2021年的報導1，台灣IC半導體相關的就業人口也不過約７％，其中台積電員工至去年也不過6萬多人2 ，而有七至八成的人在傳統產業工作。也就是說，在這些我們看到的大公司中工作的人口佔台灣的少數，受惠於這些市值大的公司給的高薪也是少數。這很可能造成貧富差距，多數人的處境和收到的薪水可能和台灣經濟的數值象徵-台指0050中是脫鉤的。另外在台灣經濟高度仰賴台積電、電子業等對電需求高的產業下，如果未來缺電可能會造成嚴重的經濟問題。\n台積電股價與元大0050的關係\n圖三\n​ 投資組合存在的本質是為了避險，這點指數型基金也不例外。但在台灣台積電一支獨秀的情況下，元大0050有將近一半的資金投在台積電真的沒問題嗎？我們可以從今年元大0050(0050.TW)和台積電(2330.TW)的收盤價歷史資料（圖三）看到，兩者走勢幾乎相同，看起來台積電的漲跌決定了元大0050的漲跌。從投資組合比例的數字大小來看，市值第二大的鴻海（持股佔比5.42%）就算上漲8.33%，對元大0050的報酬率影響也不過等於台積電上漲1%的影響，遑論其他支佔比更小的個股。實際上，在所有五十支個股中，持股佔比2%以上的股票只有四支-台積電、鴻海、聯發科、台達電 （圖四左） ; 1%以上的個股也只有22支（圖四右）。也就是說，有大概一半的個股佔元大0050投資組合比例低於1%，他們的影響力相較台積電可以說是蚍蜉撼樹。\n圖四\n圖五 元大0050在（左）2008年和（右）2019年的板塊分佈\n因此，站在分散投資的角度想，購入元大0050ETF不見得是好的選擇。自元大0050在2003年上市以來，台積電幾乎都佔投資組合的最大宗，且穩定維持佔比10-20%的區間，直到2012第四季台積電佔比開始超過20%，往後幾年台積電的佔比更是逐年增加，在2019年台積電的股價創下往年新高，在短短一年內從年初的219.5元漲到331元，在Q4年末持股佔比達到約40%。若我們觀察2008年（圖五左）和2019年（圖五右）的板塊分佈可以看到在這十年間台積電在台灣指數的佔比大幅增加，也讓台灣的產業更集中於半導體業。\n​ 到了2020年第二季台積電宣布五奈米製程量產，此後有更大量資金湧入，該年第三季持股也到達了48%，相較前一季持股整整增加了約8％，反映出短時間內市值大幅的增加。單看股價而言，自2020年3月疫情恐慌股市崩盤至隔年1月，台積電從248元上漲到673元，整整翻了2.71倍。自今年(2022)年初隨著美國一路的升息，台積電股價一路呈下跌趨勢;雪上加霜的是在今年8月時裴洛西訪台後，地緣政治風險隨之升高，在外資急於撤離的情況下一路下跌，直到最近才有止跌回升的現象。\n圖六 元大0050和台積電在（左）2019-2022年和（右）2008-2019股價\n​\n​ 我們可以比較2008年初到2018年末（圖六左）和2019年初到2020年末（圖六右）台積電和元大0050收盤價的歷史，可以很明顯地看到2019-2022這三年台積電和元大0050股價的走勢比2018年以前的十年來的更接近。這一方面是因為台積電的市值在2019年開始就大幅上升，因此增加了持股比例，讓台積電對元大0050影響力更強; 另一方面因為台積電作為台灣第一大股，且近三年幾乎已成為業界龍頭，必更受世界各地的投資者矚目，大量資金進出這支股票的情況下波動更大是一定的，也連帶影響到元大0050。在這兩種因素加成的情況下元大0050的走勢很大部分被台積電所決定，也因此才有人戲稱買元大0050其實就等於買台積電一說。\n總結\n視覺化元大0050持股比例後，我們首先能看到台灣產業資金大量集中在半導體、金融業、電子業，其中半導體產業中台積電獨佔鰲頭。從這些結論我們可以觀察到台灣就業市場潛在的貧富差距和台灣經濟命脈高度仰賴用電的問題。而從元大0050的投資組合的持股近乎一半集中在台積電，這不但反應出台灣經濟高度仰賴台積電，也讓元大0050的避險能力受到限制。萬一台積電在短時間內大量崩跌，快到元大0050來不及修正他的投資組合，減少損失，對持有這個基金的人而言必定會是場災難。因此持有這檔股票的人應該需要非常注意台積電的獲利能力和公司狀況才能真正的避開風險，可能不符合許多人對於ETF能實現「無腦投資」的期待。\n參考資料\n[1] https://ctee.com.tw/bookstore/magazine/426808.html\n[2]https://tw.stock.yahoo.com/news/%E5%8F%B0%E7%A9%8D%E9%9B%BB%E5%8E%BB%E5%B9%B4%E5%93%A1%E5%B7%A5%E5%B9%B3%E5%9D%87%E6%94%B6%E5%85%A5%E7%B4%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E8%B3%87-4-%E5%80%8D-%E4%BD%86%E9%A3%AF%E7%A2%97%E4%B8%8D%E5%A5%BD%E6%8D%A7%E3%80%8C-176-%E6%96%B0%E4%BA%BA%E9%9B%A2%E8%81%B7%E3%80%8D-122457762.html\n","permalink":"https://usausagichan.github.io/blog/0050/","tags":["Python","Tableau","Scraping"],"title":"從0050看台灣產業分佈"},{"categories":["Project"],"contents":"一間房子到底要賣多少錢才符合行情？我們最直接想到的判斷要素應該會是這個房子的地段和坪數。實際上不只這兩點，還有許多因素會影響房價。我們就用kaggle上的波士頓房價資料集來看這件事吧\n在資料前處理的部分我會\n將資料視覺化，並對資料做一些轉換和剔除不重要或互相有強烈關聯的feature 了解各feature代表的意義，適當的填入缺失值和做one-hot coding 用Lasso做feature selection 接著進入training 的環節，我使用的model是XGBoost，以5-fold cross validation選出模型合適參數，最後用train出來的模型做房價預測\n首先匯入套件和training, testing data set\n#load module, data import pandas as pd import numpy as np import sklearn as sci import matplotlib.pyplot as plt import seaborn as sns import scipy.stats as stats import xgboost as xgb from sklearn.model_selection import GridSearchCV from sklearn.linear_model import LassoCV from sklearn.feature_selection import SelectFromModel train = pd.read_csv(\u0026#34;train.csv\u0026#34;) test = pd.read_csv(\u0026#34;test.csv\u0026#34;) Data Cleaning： 我將training和testing data的feature先合併以利接下來做統一處理，除了方便外也可以避免分開做歸一化會有尺度不相同的問題\ndtrain=train.drop([\u0026#39;SalePrice\u0026#39;],axis=1) database=pd.concat([dtrain,test]) 首先我大致將資料分為’object_type’(qualitative)和’numerical_type’(quantative)\n而由官網中data_description檔案對各feature的細節描述，\nhttps://drive.google.com/file/d/17sT4kM4qbzHlQ9zO-V1ZK81Gdlm8YVQ6/view?usp=sharing\n可以得知feature ‘MSSubClass’中的整數事實上是代表房屋交易的不同類別，並且數字大小和他的實際意義完全沒有關係，所以要把他的資料類別改成字串\n#datacleaning realobj=[\u0026#39;MSSubClass\u0026#39;] database[realobj]=database[realobj].astype(str) quant = [f for f in database.columns if database.dtypes[f] != \u0026#39;object\u0026#39;] quali = [f for f in database.columns if database.dtypes[f] == \u0026#39;object\u0026#39;] 判定其中存在缺失的column為\nIndex([**\u0026#39;TotalBsmtSF\u0026#39;, \u0026#39;GarageArea\u0026#39;, \u0026#39;GarageCars\u0026#39;**, \u0026#39;KitchenQual\u0026#39;, \u0026#39;Electrical\u0026#39;, **\u0026#39;BsmtUnfSF\u0026#39;, \u0026#39;BsmtFinSF2\u0026#39;, \u0026#39;BsmtFinSF1\u0026#39;**, \u0026#39;SaleType\u0026#39;, \u0026#39;Exterior1st\u0026#39;, \u0026#39;Exterior2nd\u0026#39;, \u0026#39;Functional\u0026#39;, \u0026#39;Utilities\u0026#39;, **\u0026#39;BsmtHalfBath\u0026#39;, \u0026#39;BsmtFullBath\u0026#39;**, \u0026#39;MSZoning\u0026#39;, **\u0026#39;MasVnrArea\u0026#39;**, \u0026#39;**MasVnrType\u0026#39;**, \u0026#39;**BsmtFinType1**\u0026#39;, \u0026#39;**BsmtFinType2**\u0026#39;, \u0026#39;**BsmtQual**\u0026#39;, \u0026#39;**BsmtCond**\u0026#39;, \u0026#39;**BsmtExposure**\u0026#39;, \u0026#39;**GarageType**\u0026#39;, \u0026#39;**GarageCond**\u0026#39;, \u0026#39;**GarageQual**\u0026#39;, \u0026#39;**GarageYrBlt**\u0026#39;, \u0026#39;**GarageFinish**\u0026#39;, \u0026#39;LotFrontage\u0026#39;, \u0026#39;**FireplaceQu**\u0026#39;, **\u0026#39;Fence\u0026#39;, \u0026#39;Alley**\u0026#39;, **\u0026#39;MiscFeature\u0026#39;**, \u0026#39;**PoolQC**\u0026#39;] 某些feature中的’NA’代表本身無該項feature，但pandas會把他判定成資料有缺失，對於這類feature ‘object_type’要置換成type-’None’，’numerical_type’要補零，比如’Pool QC’ (Pool Quality)的’NA’值代表沒有泳池，把NA改成’None’即可，其餘的缺失值’object_type’用該column的眾數補上，’numerical_type’則用該column平均值補上\nnon=[\u0026#39;PoolQC\u0026#39;, \u0026#39;MiscFeature\u0026#39;, \u0026#39;Alley\u0026#39;, \u0026#39;Fence\u0026#39;, \u0026#39;FireplaceQu\u0026#39;, \u0026#39;GarageCond\u0026#39;, \u0026#39;GarageQual\u0026#39;, \u0026#39;GarageFinish\u0026#39;, \u0026#39;GarageType\u0026#39;, \u0026#39;BsmtCond\u0026#39;, \u0026#39;BsmtExposure\u0026#39;, \u0026#39;BsmtQual\u0026#39;, \u0026#39;BsmtFinType1\u0026#39;, \u0026#39;BsmtFinType2\u0026#39;,\u0026#39;MasVnrType\u0026#39;] zerof=[\u0026#39;TotalBsmtSF\u0026#39;, \u0026#39;GarageArea\u0026#39;, \u0026#39;GarageCars\u0026#39;,\u0026#39;BsmtUnfSF\u0026#39;, \u0026#39;BsmtFinSF2\u0026#39;, \u0026#39;BsmtFinSF1\u0026#39;,\u0026#39;BsmtHalfBath\u0026#39;, \u0026#39;BsmtFullBath\u0026#39;,\u0026#39;MasVnrArea\u0026#39;] needfill=[\u0026#39;KitchenQual\u0026#39;,\u0026#39;Electrical\u0026#39;,\u0026#39;SaleType\u0026#39;,\u0026#39;Exterior1st\u0026#39;,\u0026#39;Exterior2nd\u0026#39;,\u0026#39;Functional\u0026#39;, \u0026#39;Utilities\u0026#39;,\u0026#39;MSZoning\u0026#39;]#front: numerical_type_feature backw: objective_type_feature front=database[quant] front[zerof]=front[zerof].fillna(0) front[\u0026#39;LotFrontage\u0026#39;]=front[\u0026#39;LotFrontage\u0026#39;].fillna(front[\u0026#39;LotFrontage\u0026#39;].mean())backw=database[quali] for x in needfill: backw[x]=backw[x].fillna(backw[x].mode()[0]) backw[non]=backw[non].fillna(\u0026#39;None\u0026#39;) 視覺化各統計資料： ‘numerical_type_feature’數值分佈圖 c= [f for f in database.columns if database.dtypes[f] != \u0026#39;object\u0026#39;] c.remove(\u0026#39;Id\u0026#39;) f = pd.melt(front, value_vars=c) g = sns.FacetGrid(f, col=\u0026#34;variable\u0026#34;, col_wrap=4 , sharex=False, sharey=False) g = g.map(sns.distplot, \u0026#34;value\u0026#34;) 在這些分佈圖中，我們可以看出’LotFrontage’, ‘LotArea’ ,’1stFlrSF’ ,’GrLivArea’的分佈較接近log normal distribution，因此可以先將這些column的數值取log，使資料的分佈接近常態分佈，接著再對所有numerical_type_feature做normalization\n另外’BsmtFinSF2\u0026rsquo;, ‘LowQualFinSF’, ‘BsmtHalfBath’, ‘KitchenAbvGr’, ‘EnclosedPorch’, ‘3SsnPorch’, ‘ScreenPorch’, ‘PoolArea’, ‘MiscVal’值非常集中且單一，無法從中得到資訊，可納入刪除名單\nlogtran=[\u0026#39;LotFrontage\u0026#39;,\u0026#39;LotArea\u0026#39;,\u0026#39;1stFlrSF\u0026#39;,\u0026#39;GrLivArea\u0026#39;] front[logtran]=np.log(front[logtran]) front=(front-front.mean())/(front.std()) 觀察Sale Price的數據，會發現它的分布是比較偏斜的，這樣的資料不利於Training，因為預測結果大量集中在某個區間範圍除了可能會讓機器忽略其他較離散的數值，也會讓機器較難分辨出不同feature對應到的不同預測值。這時我們通常會取log讓預測值的分佈散開。實際上、當我們將Sale Price的分佈對做擬合會發現它的分布其實很接近log normal distribution (即取log 後成常態分佈)\ny = train[\u0026#39;SalePrice\u0026#39;] plt.figure(2); plt.title(\u0026#39;Normal\u0026#39;) sns.distplot(y, kde=False, fit=stats.norm) plt.figure(3); plt.title(\u0026#39;Log Normal\u0026#39;) sns.distplot(y, kde=False, fit=stats.lognorm)trainresult=np.log(data[\u0026#39;SalePrice\u0026#39;]) 繪製numerical_feature和Sale_Price的熱力圖觀察feature間的相關性大小：\nplt.figure(figsize=(16, 16)) front=front.drop(\u0026#39;Id\u0026#39;,axis=1) front[\u0026#39;SalePrice\u0026#39;]=np.log(train[\u0026#39;SalePrice\u0026#39;]) corr = front.corr() sns.heatmap(corr,cmap=\u0026#34;viridis\u0026#34;) 由上圖可看出TotalBsmt和1stFLSF，garage_area和garage_car有強烈關聯性，依據常理推斷是因為地下室總面積和第一層樓的面積大多數情況應是相同的，而garage面積愈大garage_car也會愈多\n另外’OverallQual’ , ‘GrLivArea’和’Sale_Price’ 相關性比較大，可推測’OverallQual’ , ‘GrLivArea’會是training過程中權重較大的重要feature\n至於看起來不太重要的feature（整列顏色都很黯淡）有：\n‘BsmtFinSF2’, ‘LowQualFinSF’, ‘BsmtHalfBath’, ‘KitchenAbvGr’, ‘EnclosedPorch’, ‘3SsnPorch’, ‘ScreenPorch’, ‘PoolArea’, ‘MiscVal等等\n而以上提及的這些不重要的feature正是前面提到『分佈非常集中且單一』的feature\n另外也可看出’MoSold’ ‘YrSold’不太重要，可見銷售時間對房價沒有太大影響\n接著對’object_type’ feature做one-hot coding，並將’object_type’和’numerical_type’ feature\n重新組回單一dataframe，之後剔除根據data_visualization的結果判定不重要的feature\n除此之外，某些’object_type’ feature中標示為None的對象是重複的，比如同筆交易資料顯示房子無Garage，則該筆資料中’GarageCond’, ‘GarageQual’, ‘GarageFinish’, ‘GarageType’通通都會是’None’，而經過one-hot coding處理後會產生’GarageCond_None’, ‘GarageQual_None’, ‘GarageFinish_None’ , ‘GarageType_None’等feature，此時這筆資料在這些feature中值通通都是1因；若該筆交易資料的房子有Garage則為零，即這些feature的值完全相同。因此我們只要保留一個feature即可\nbackw=pd.get_dummies(backw) databass=pd.concat([front,backw],axis=1) delete_feature=[\u0026#39;MoSold\u0026#39;, \u0026#39;YrSold\u0026#39;,\u0026#39;Id\u0026#39;,\u0026#39;BsmtHalfBath\u0026#39;, \u0026#39;KitchenAbvGr\u0026#39;, \u0026#39;EnclosedPorch\u0026#39;, \u0026#39;3SsnPorch\u0026#39;, \u0026#39;ScreenPorch\u0026#39;, \u0026#39;PoolArea\u0026#39;, \u0026#39;MiscVal\u0026#39;,\u0026#39;1stFlrSF\u0026#39;,\u0026#39;GarageArea\u0026#39;,\u0026#39;LowQualFinSF\u0026#39;, \u0026#39;BsmtFinSF2\u0026#39;,\u0026#39;GarageYrBlt\u0026#39;] repeatnon=[ \u0026#39;GarageCond_None\u0026#39;,\u0026#39;GarageQual_None\u0026#39;, \u0026#39;GarageFinish_None\u0026#39;, \u0026#39;GarageType_None\u0026#39;, \u0026#39;BsmtCond_None\u0026#39;,\u0026#39;BsmtExposure_None\u0026#39;, \u0026#39;BsmtQual_None\u0026#39;, \u0026#39;BsmtFinType1_None\u0026#39;, \u0026#39;BsmtFinType2_None\u0026#39;,\u0026#39;MasVnrType_None\u0026#39;] databass=databass.drop(delete_feature,axis=1) databass=databass.drop(repeatnon,axis=1) ‘numerical_type_feature’對Sale-Price的scatter plot def scatter(x,y,**kwargs): sns.scatterplot(x,y) c= [f for f in database.columns if database.dtypes[f] != \u0026#39;object\u0026#39;] c.remove(\u0026#39;Id\u0026#39;) front[\u0026#39;SalePrice\u0026#39;]=train[\u0026#39;SalePrice\u0026#39;] f = pd.melt(front, id_vars=[\u0026#39;SalePrice\u0026#39;],value_vars=c) g = sns.FacetGrid(f, col=\u0026#34;variable\u0026#34;, col_wrap=4 , sharex=False, sharey=False) g = g.map(scatter, \u0026#34;value\u0026#34;,\u0026#39;SalePrice\u0026#39;) 從上面這些圖來看，觀察前文分析出來可能較重要的feature: ‘OverallQual’ , ‘GrLivArea’，可發現在’OverallQual’最大的情況下有兩個點SalePrice偏低， 同樣的情況也可見於’GrLivArea’，這兩個點index為523及1298，明顯不符常理和其他點的趨勢，為異常值應去除\n用Lasso選取重要feature: Lasso是一種透過加入一次懲罰係數做regularization的線性模型，而在經過training後不重要的feature係數會變成零，是常被用來做feature selection的方式。並且，在training同時可以透過GridSearchCV的方式去找最合適的懲罰項係數，讓train出來最準確的模型判斷feature的重要性，留下權重大於0的項\n#feature_selection by Lasso() pipeline = Pipeline([(\u0026#39;scaler\u0026#39;,StandardScaler()),(\u0026#39;model\u0026#39;,Lasso())]) search = GridSearchCV(pipeline,{\u0026#39;model__alpha\u0026#39;:np.arange(1e-3,1e-2,1e-4)}, cv = 5, scoring=\u0026#34;neg_mean_squared_error\u0026#34;,verbose=5) search.fit(databass.iloc[:1458], trainresult) print(search.best_params_) coefficients = search.best_estimator_.named_steps[\u0026#39;model\u0026#39;].coef_ importance = np.abs(coefficients) feature=databass.columns evaluate=pd.DataFrame({\u0026#39;feature\u0026#39;:feature,\u0026#39;importance\u0026#39;:importance}) drop=evaluate[evaluate[\u0026#39;importance\u0026#39;]==0] databass=databass.drop(drop[\u0026#39;feature\u0026#39;],axis=1) Training Process: 在training process 中，我一共用了四個線性模型（Ridge, Lasso, Elastic Net, SVM Regressor）和兩個Boosting模型（Gradient Boosting, XGB）以及以前述六個模型當作第一階段的regressor，XGB演算法做第二階段的meta regressor做stacking，然後將stacking的模型和其他模型一起做blending\n重新將training和testing data分開，定義cv_rmse_function為接下來評估各model使用的方法-10-fold cross validation做準備\ntrainfeature=databass[:1458] #2 outlier removed testfeature=databass[1458:] #define functions in training process kfolds = KFold(n_splits=10, shuffle=True, random_state=42)def cv_rmse(model, X, y): rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\u0026#34;neg_mean_squared_error\u0026#34;, cv=kfolds)) return (rmse) 設定六種模型的參數值，在linear model上使用RobustScaler()減少離群值對training process的影響及stacking的方式（first stage regressor=ridge, lasso, elasticnet,svr, gbr, xgbr, meta regressor= XGB）\nalphas_alt = np.arange(14,16,0.1) alphas2 = [0.003, 0.004, 0.005] e_alphas = np.arange(1e-4,1e-3,1e-4) e_l1ratio = np.arange(0.8,1,0.25)ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds)) lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds)) elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio)) svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,)) xgbr= xgb.XGBRegressor(learning_rate= 0.01, max_depth= 3, n_estimators= 2500,objective=\u0026#39;reg:linear\u0026#39;) gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features=\u0026#39;sqrt\u0026#39;, min_samples_leaf=15, min_samples_split=10, loss=\u0026#39;huber\u0026#39;, random_state =42) stackr = StackingCVRegressor(regressors=(ridge, lasso, elasticnet,svr, gbr, xgbr), meta_regressor=xgbr,use_features_in_secondary=True) 分別得到六個模型在training data set上的10-fold cross validation error，並記錄下來，當作後面做blending比例的參考\ns=[] score = cv_rmse(ridge,trainfeature, trainresult) s.append(1/score.mean()) print(\u0026#34;Ridge: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std()) ) score = cv_rmse(lasso,trainfeature, trainresult) s.append(1/score.mean()) print(\u0026#34;LASSO: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std())) score = cv_rmse(elasticnet,trainfeature, trainresult) print(\u0026#34;elastic net: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std()) ) s.append(1/score.mean()) score = cv_rmse(svr,trainfeature, trainresult) print(\u0026#34;SVR: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std())) s.append(1/score.mean()) score = cv_rmse(xgbr,trainfeature, trainresult) print(\u0026#34;xgboost: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std())) s.append(1/score.mean()) score = cv_rmse(gbr,trainfeature, trainresult) print(\u0026#34;gboost: {:.4f} ({:.4f})\\\\n\u0026#34;.format(score.mean(), score.std())) s.append(1/score.mean()) 讓七個模型各自做training\nlasso_mod= lasso.fit(trainfeature, trainresult) ridge_mod= ridge.fit(trainfeature, trainresult) elasticnet_mod= elasticnet.fit(trainfeature, trainresult) svr_mod = svr.fit(trainfeature, trainresult) xgb_mod= xgbr.fit(trainfeature, trainresult) gbr_mod= gbr.fit(trainfeature, trainresult) stack_mod= stackr.fit(np.array(trainfeature), np.array(trainresult)) 以六個模型（Ridge, Lasso, Elastic Net, SVM Regressor）依據各自的10-fold cross validation error的倒數做加總（註：為使error愈大的模型權重排名愈小，error愈小權重愈大），最後再與Stacking的模型做平均得到最終predict的結果\n#blending s=(s/np.sum(s)) def blend_predict(X): return np.exp(0.5*((s[0] * ridge_mod.predict(X))+ (s[1] * lasso_mod.predict(X)) + (s[2] * elasticnet_mod.predict(X)) + (s[3] * svr_mod.predict(X)) + (s[4] * xgb_mod.predict(X))+(s[5] * gbr_mod.predict(X)))+0.5*stack_mod.predict(np.array(X))) testresult=blend_predict(testfeature) 最後predict結果的public score大約是0.1243（score的計算方式為將預測值和實際值取log後計算mean square error，這樣取log後算error的好處是error值不會受房價本身大小的影響，因此可以用來衡量不同數量級房價預測的準確性）\n","permalink":"https://usausagichan.github.io/blog/houseprice/","tags":["Python","Machine Learning","Scilit-Learn","Data Visualization"],"title":"kaggle-波士頓房價預測"}]